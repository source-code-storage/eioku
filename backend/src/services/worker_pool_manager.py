"""Worker pool management for video processing tasks."""

import threading
import time
from collections.abc import Callable
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING, Any

from ..domain.artifacts import Run
from ..domain.models import Task
from ..utils.print_logger import get_logger
from .task_orchestration import TaskType
from .task_orchestrator import TaskOrchestrator

if TYPE_CHECKING:
    from ..repositories.video_repository import SqlVideoRepository as VideoRepository
    from .object_detection_task_handler import ObjectDetectionTaskHandler

logger = get_logger(__name__)


class ResourceType(Enum):
    """Resource types for workers."""

    CPU = "cpu"
    GPU = "gpu"
    IO = "io"


@dataclass
class WorkerConfig:
    """Configuration for a worker pool."""

    task_type: TaskType
    worker_count: int
    resource_type: ResourceType
    priority: int


class TaskWorker:
    """Base class for task workers."""

    def __init__(self, task_type: TaskType):
        self.task_type = task_type
        self.logger = get_logger(f"worker.{task_type.value}")

    def execute_task(self, task: Task) -> dict:
        """Execute a task and return result."""
        self.logger.info(f"Starting {self.task_type.value} task {task.task_id}")

        try:
            # Task is already marked as running by atomic dequeue

            # Execute the actual work
            result = self._do_work(task)

            # Mark task as completed
            task.complete()

            self.logger.info(f"Completed {self.task_type.value} task {task.task_id}")
            return {"status": "success", "result": result}

        except Exception as e:
            error_msg = str(e)
            task.fail(error_msg)
            self.logger.error(
                f"Failed {self.task_type.value} task {task.task_id}: {error_msg}"
            )
            return {"status": "error", "error": error_msg}

    def _do_work(self, task: Task) -> Any:
        """Override this method to implement actual work."""
        # Simulate work for now
        time.sleep(0.1)
        return f"Processed {self.task_type.value} for video {task.video_id}"


class HashWorker(TaskWorker):
    """Worker for hash calculation tasks."""

    def __init__(self, hash_service=None, video_repository=None):
        super().__init__(TaskType.HASH)
        from .file_hash_service import FileHashService

        self.hash_service = hash_service or FileHashService()
        self.video_repository = video_repository

    def _do_work(self, task: Task) -> str:
        """Calculate file hash."""
        # Get video from repository to get the file path
        if not self.video_repository:
            raise RuntimeError("HashWorker requires a video_repository")

        video = self.video_repository.find_by_id(task.video_id)
        if not video:
            raise RuntimeError(f"Video not found: {task.video_id}")

        try:
            hash_value = self.hash_service.calculate_hash(video.file_path)
            logger.info(f"Calculated hash for {task.video_id}: {hash_value}")

            # Update video with hash
            video.file_hash = hash_value
            self.video_repository.save(video)

            return hash_value
        except Exception as e:
            logger.error(f"Hash calculation failed for {task.video_id}: {e}")
            raise


class TranscriptionWorker(TaskWorker):
    """Worker for transcription tasks."""

    def __init__(
        self,
        transcription_handler=None,
        video_repository=None,
        model_profile: str = "balanced",
    ):
        super().__init__(TaskType.TRANSCRIPTION)
        self.transcription_handler = transcription_handler
        self.video_repository = video_repository
        self.model_profile = model_profile

    def _do_work(self, task: Task) -> dict:
        """Perform transcription using Whisper."""
        if not self.transcription_handler:
            raise RuntimeError("TranscriptionWorker requires a transcription_handler")

        if not self.video_repository:
            raise RuntimeError("TranscriptionWorker requires a video_repository")

        # Get video from repository
        video = self.video_repository.find_by_id(task.video_id)
        if not video:
            raise RuntimeError(f"Video not found: {task.video_id}")

        # Process transcription with model_profile
        success = self.transcription_handler.process_transcription_task(
            task, video, model_profile=self.model_profile
        )

        if not success:
            raise RuntimeError("Transcription processing failed")

        # Get transcription segments for result
        segments = self.transcription_handler.get_transcription_segments(task.video_id)

        return {
            "segments_count": len(segments),
            "total_text_length": len(
                self.transcription_handler.get_transcription_text(task.video_id)
            ),
        }


class SceneDetectionWorker(TaskWorker):
    """Worker for scene detection tasks."""

    def __init__(
        self,
        scene_detection_service=None,
        video_repository=None,
        artifact_repository=None,
        run_repository=None,
    ):
        super().__init__(TaskType.SCENE_DETECTION)
        self.scene_detection_service = scene_detection_service
        self.video_repository = video_repository
        self.artifact_repository = artifact_repository
        self.run_repository = run_repository

    def _do_work(self, task: Task) -> dict:
        """Perform scene detection."""
        logger.info(f"Scene detection worker starting for task {task.task_id}")

        if not self.scene_detection_service:
            raise RuntimeError(
                "SceneDetectionWorker requires a scene_detection_service"
            )

        if not self.video_repository:
            raise RuntimeError("SceneDetectionWorker requires a video_repository")

        if not self.artifact_repository:
            raise RuntimeError("SceneDetectionWorker requires an artifact_repository")

        if not self.run_repository:
            raise RuntimeError("SceneDetectionWorker requires a run_repository")

        # Get video from repository
        logger.debug(f"Fetching video {task.video_id} from repository")
        video = self.video_repository.find_by_id(task.video_id)
        if not video:
            raise RuntimeError(f"Video not found: {task.video_id}")

        # Create a run for this scene detection task
        import uuid
        from datetime import datetime

        run_id = str(uuid.uuid4())
        run = Run(
            run_id=run_id,
            asset_id=video.video_id,
            pipeline_profile="balanced",  # Default profile
            started_at=datetime.utcnow(),
            status="running",
        )
        self.run_repository.create(run)

        try:
            logger.info(f"Detecting scenes in {video.file_path}")
            # Detect scenes and get artifacts
            artifacts = self.scene_detection_service.detect_scenes(
                video.file_path, video.video_id, run_id, model_profile="balanced"
            )

            logger.info(f"Storing {len(artifacts)} scene artifacts in database")
            # Store artifacts in database
            for artifact in artifacts:
                self.artifact_repository.create(artifact)

            # Mark run as completed
            run.complete(datetime.utcnow())
            self.run_repository.update(run)

            # Get scene statistics
            scene_info = self.scene_detection_service.get_scene_info(artifacts)

            logger.info(
                f"Detected and stored {scene_info['scene_count']} scenes "
                f"for video {task.video_id}"
            )

            return scene_info

        except Exception as e:
            # Mark run as failed
            run.fail(str(e), datetime.utcnow())
            self.run_repository.update(run)
            raise

        return scene_info


class ObjectDetectionWorker(TaskWorker):
    """Worker for object detection tasks."""

    def __init__(
        self,
        detection_handler: "ObjectDetectionTaskHandler",
        video_repository: "VideoRepository",
        model_profile: str = "balanced",
    ):
        super().__init__(TaskType.OBJECT_DETECTION)
        self.detection_handler = detection_handler
        self.video_repository = video_repository
        self.model_profile = model_profile

    def _do_work(self, task: Task) -> dict:
        """Perform object detection."""
        # Get video
        video = self.video_repository.find_by_id(task.video_id)
        if not video:
            raise ValueError(f"Video not found: {task.video_id}")

        # Process object detection with model_profile
        success = self.detection_handler.process_object_detection_task(
            task, video, model_profile=self.model_profile
        )

        if not success:
            raise Exception("Object detection processing failed")

        # Get detected objects for response
        objects = self.detection_handler.get_detected_objects(task.video_id)

        return {
            "objects_detected": len(objects),
            "unique_labels": len(set(obj.label for obj in objects)),
        }


class FaceDetectionWorker(TaskWorker):
    """Worker for face detection tasks."""

    def __init__(
        self,
        detection_handler,
        video_repository: "VideoRepository",
    ):
        super().__init__(TaskType.FACE_DETECTION)
        self.detection_handler = detection_handler
        self.video_repository = video_repository

    def _do_work(self, task: Task) -> dict:
        """Perform face detection."""
        # Get video
        video = self.video_repository.find_by_id(task.video_id)
        if not video:
            raise ValueError(f"Video not found: {task.video_id}")

        # Process face detection
        success = self.detection_handler.process_face_detection_task(task, video)

        if not success:
            raise Exception("Face detection processing failed")

        # Get detected faces for response
        faces = self.detection_handler.get_detected_faces(task.video_id)

        # Calculate total face occurrences
        total_occurrences = sum(face.get_occurrence_count() for face in faces)

        return {
            "face_groups": len(faces),
            "total_occurrences": total_occurrences,
        }


class WorkerPool:
    """Manages a pool of workers for a specific task type."""

    def __init__(
        self,
        config: WorkerConfig,
        orchestrator: TaskOrchestrator,
        task_settings: dict | None = None,
        profile_name: str = "balanced",
    ):
        self.config = config
        self.orchestrator = orchestrator
        self.task_settings = task_settings or {}
        self.profile_name = profile_name  # Store profile name for model_profile
        self.is_running = False
        self.workers = []
        self.executor = None
        self._stop_event = threading.Event()

        # Create worker instances
        self.worker_factory = self._get_worker_factory()

    def start(self) -> None:
        """Start the worker pool."""
        if self.is_running:
            return

        self.is_running = True
        self._stop_event.clear()

        # Use thread pool for all tasks to avoid pickling issues with database sessions
        self.executor = ThreadPoolExecutor(max_workers=self.config.worker_count)

        # Start worker threads with jitter to prevent simultaneous polling
        import random

        for i in range(self.config.worker_count):
            # Add random jitter (0-5 seconds) to stagger worker startup
            jitter = random.uniform(0, 5)

            worker_thread = threading.Thread(
                target=self._worker_loop,
                name=f"{self.config.task_type.value}-worker-{i}",
                args=(jitter,),
                daemon=True,
            )
            worker_thread.start()
            self.workers.append(worker_thread)

        logger.info(
            f"Started {self.config.worker_count} workers for "
            f"{self.config.task_type.value}"
        )

    def stop(self) -> None:
        """Stop the worker pool."""
        if not self.is_running:
            return

        self.is_running = False
        self._stop_event.set()

        # Shutdown executor
        if self.executor:
            self.executor.shutdown(wait=True)

        # Wait for worker threads to finish
        for worker in self.workers:
            worker.join(timeout=5.0)

        self.workers.clear()
        logger.info(f"Stopped worker pool for {self.config.task_type.value}")

    def _worker_loop(self, initial_jitter: float = 0) -> None:
        """Main loop for worker threads."""
        from ..database.connection import get_db
        from ..repositories.task_repository import SQLAlchemyTaskRepository
        from ..repositories.video_repository import SqlVideoRepository

        # Apply initial jitter to stagger worker startup
        if initial_jitter > 0:
            time.sleep(initial_jitter)
            logger.info(
                f"Worker loop started for {self.config.task_type.value} "
                f"(jitter: {initial_jitter:.2f}s)"
            )
        else:
            logger.info(f"Worker loop started for {self.config.task_type.value}")

        # Create session and repositories for this worker thread
        # Single session is shared with the worker to reduce connection usage
        session = next(get_db())
        video_repo = SqlVideoRepository(session)
        task_repo = SQLAlchemyTaskRepository(session)

        # Pass session to worker factory so it reuses the same connection
        worker = self.worker_factory(session)

        try:
            while self.is_running and not self._stop_event.is_set():
                try:
                    # Get next task from database atomically
                    logger.debug(f"Checking for {self.config.task_type.value} tasks...")

                    # Use atomic dequeue to prevent race conditions
                    task = task_repo.atomic_dequeue_pending_task(
                        self.config.task_type.value
                    )

                    if task is None:
                        # No tasks available, wait a bit
                        time.sleep(30.0)
                        continue

                    logger.info(
                        f"Found task {task.task_id} for {self.config.task_type.value}"
                    )
                    # Submit task to executor
                    future = self.executor.submit(worker.execute_task, task)

                    # Wait for completion and handle result
                    try:
                        result = future.result(timeout=300)  # 5 minute timeout

                        if result["status"] == "success":
                            # Update task status in database
                            task.complete()
                            task_repo.update(task)

                            # Update video status if this was a hash task
                            if self.config.task_type == TaskType.HASH:
                                video = video_repo.find_by_id(task.video_id)
                                if video:
                                    video.status = "hashed"
                                    video_repo.save(video)
                                    logger.info(
                                        f"Updated video {task.video_id} to hashed"
                                    )

                                    # Create next tasks for the video using orchestrator
                                    new_tasks = (
                                        self.orchestrator.create_tasks_for_video(video)
                                    )
                                    if new_tasks:
                                        logger.info(
                                            f"Created {len(new_tasks)} new tasks"
                                        )
                                        for new_task in new_tasks:
                                            logger.info(
                                                f"   - {new_task.task_type} task"
                                            )

                            task_type = self.config.task_type.value
                            logger.info(f"Completed {task_type} task {task.task_id}")
                        else:
                            # Update task as failed
                            task.fail(result["error"])
                            task_repo.update(task)
                            logger.error(
                                f"Task {task.task_id} failed: {result['error']}"
                            )

                    except Exception as e:
                        error_msg = f"Worker execution failed: {str(e)}"
                        task.fail(error_msg)
                        task_repo.update(task)
                        logger.error(f"Task {task.task_id} failed: {error_msg}")

                except Exception as e:
                    logger.error(f"Worker loop error: {e}")
                    time.sleep(1.0)  # Prevent tight error loops
        finally:
            session.close()

    def _get_worker_factory(self) -> Callable[..., TaskWorker]:
        """Get worker factory for task type.

        All factories accept a session parameter to reuse the connection
        from the worker loop, reducing database connection usage.
        """
        if self.config.task_type == TaskType.HASH:
            from ..repositories.video_repository import SqlVideoRepository
            from .file_hash_service import FileHashService

            def create_hash_worker(session):
                video_repo = SqlVideoRepository(session)
                hash_service = FileHashService()
                return HashWorker(
                    hash_service=hash_service, video_repository=video_repo
                )

            return create_hash_worker
        elif self.config.task_type == TaskType.TRANSCRIPTION:
            from ..repositories.transcription_repository import (
                SqlTranscriptionRepository,
            )
            from ..repositories.video_repository import SqlVideoRepository
            from .audio_extraction_service import AudioExtractionService
            from .transcription_task_handler import TranscriptionTaskHandler
            from .whisper_transcription_service import WhisperTranscriptionService

            # Create transcription handler with dependencies
            def create_transcription_worker(session):
                video_repo = SqlVideoRepository(session)
                transcription_repo = SqlTranscriptionRepository(session)
                audio_service = AudioExtractionService()
                whisper_service = WhisperTranscriptionService()
                transcription_handler = TranscriptionTaskHandler(
                    transcription_repository=transcription_repo,
                    audio_service=audio_service,
                    whisper_service=whisper_service,
                )
                return TranscriptionWorker(
                    transcription_handler=transcription_handler,
                    video_repository=video_repo,
                    model_profile=self.profile_name,
                )

            return create_transcription_worker
        elif self.config.task_type == TaskType.SCENE_DETECTION:
            from ..repositories.scene_repository import SqlSceneRepository
            from ..repositories.video_repository import SqlVideoRepository
            from .scene_detection_service import SceneDetectionService

            # Create scene detection worker with dependencies
            def create_scene_detection_worker(session):
                video_repo = SqlVideoRepository(session)
                scene_repo = SqlSceneRepository(session)
                scene_detection_service = SceneDetectionService()
                return SceneDetectionWorker(
                    scene_detection_service=scene_detection_service,
                    video_repository=video_repo,
                    scene_repository=scene_repo,
                )

            return create_scene_detection_worker
        elif self.config.task_type == TaskType.OBJECT_DETECTION:
            from ..domain.schema_registry import SchemaRegistry
            from ..repositories.artifact_repository import SqlArtifactRepository
            from ..repositories.video_repository import SqlVideoRepository
            from ..services.projection_sync_service import ProjectionSyncService
            from .object_detection_service import ObjectDetectionService
            from .object_detection_task_handler import ObjectDetectionTaskHandler

            # Get settings from task_settings
            model_name = self.task_settings.get("object_detection_model", "yolov8n.pt")
            sample_rate = self.task_settings.get("frame_sampling_interval", 30)

            # Create object detection worker with dependencies
            def create_object_detection_worker(session):
                video_repo = SqlVideoRepository(session)
                schema_registry = SchemaRegistry()
                projection_sync = ProjectionSyncService(session)
                artifact_repo = SqlArtifactRepository(
                    session, schema_registry, projection_sync
                )
                detection_service = ObjectDetectionService(model_name=model_name)
                detection_handler = ObjectDetectionTaskHandler(
                    artifact_repository=artifact_repo,
                    schema_registry=schema_registry,
                    detection_service=detection_service,
                    model_name=model_name,
                    sample_rate=sample_rate,
                )
                return ObjectDetectionWorker(
                    detection_handler=detection_handler,
                    video_repository=video_repo,
                    model_profile=self.profile_name,
                )

            return create_object_detection_worker
        elif self.config.task_type == TaskType.FACE_DETECTION:
            from ..repositories.face_repository import SQLAlchemyFaceRepository
            from ..repositories.video_repository import SqlVideoRepository
            from .face_detection_service import FaceDetectionService
            from .face_detection_task_handler import FaceDetectionTaskHandler

            # Get settings from task_settings
            model_name = self.task_settings.get(
                "face_detection_model", "yolov8n-face.pt"
            )
            sample_rate = self.task_settings.get("frame_sampling_interval", 30)

            # Create face detection worker with dependencies
            def create_face_detection_worker(session):
                video_repo = SqlVideoRepository(session)
                face_repo = SQLAlchemyFaceRepository(session)
                detection_service = FaceDetectionService(model_name=model_name)
                detection_handler = FaceDetectionTaskHandler(
                    face_repository=face_repo,
                    detection_service=detection_service,
                    model_name=model_name,
                    sample_rate=sample_rate,
                )
                return FaceDetectionWorker(
                    detection_handler=detection_handler,
                    video_repository=video_repo,
                )

            return create_face_detection_worker
        else:
            # Generic workers for other task types - need to pass task_type
            task_type = self.config.task_type

            def create_generic_worker(session):
                return TaskWorker(task_type)

            return create_generic_worker


class WorkerPoolManager:
    """Manages multiple worker pools."""

    def __init__(
        self,
        orchestrator: TaskOrchestrator,
        task_settings: dict | None = None,
        profile_name: str = "balanced",
    ):
        self.orchestrator = orchestrator
        self.task_settings = task_settings or {}
        self.profile_name = profile_name  # Store profile name for model_profile
        self.pools: dict[TaskType, WorkerPool] = {}
        self.is_running = False

    def add_worker_pool(self, config: WorkerConfig) -> None:
        """Add a worker pool for a task type."""
        if config.task_type in self.pools:
            raise ValueError(f"Worker pool for {config.task_type.value} already exists")

        pool = WorkerPool(
            config, self.orchestrator, self.task_settings, self.profile_name
        )
        self.pools[config.task_type] = pool

        # Start pool if manager is running
        if self.is_running:
            pool.start()

        logger.info(f"Added worker pool for {config.task_type.value}")

    def start_all(self) -> None:
        """Start all worker pools."""
        if self.is_running:
            return

        self.is_running = True

        for pool in self.pools.values():
            pool.start()

        logger.info(f"Started {len(self.pools)} worker pools")

    def stop_all(self) -> None:
        """Stop all worker pools."""
        if not self.is_running:
            return

        self.is_running = False

        for pool in self.pools.values():
            pool.stop()

        logger.info("Stopped all worker pools")

    def get_status(self) -> dict[str, dict]:
        """Get status of all worker pools."""
        status = {}
        for task_type, pool in self.pools.items():
            status[task_type.value] = {
                "worker_count": pool.config.worker_count,
                "resource_type": pool.config.resource_type.value,
                "is_running": pool.is_running,
                "active_workers": len([w for w in pool.workers if w.is_alive()]),
            }
        return status

    def create_default_pools(self) -> None:
        """Create default worker pools with balanced configuration."""
        default_configs = [
            WorkerConfig(TaskType.HASH, 4, ResourceType.CPU, 1),
            WorkerConfig(TaskType.TRANSCRIPTION, 2, ResourceType.CPU, 2),
            WorkerConfig(TaskType.SCENE_DETECTION, 2, ResourceType.CPU, 3),
            WorkerConfig(TaskType.OBJECT_DETECTION, 2, ResourceType.GPU, 3),
            WorkerConfig(TaskType.FACE_DETECTION, 2, ResourceType.GPU, 3),
            WorkerConfig(TaskType.TOPIC_EXTRACTION, 1, ResourceType.CPU, 4),
            WorkerConfig(TaskType.EMBEDDING_GENERATION, 2, ResourceType.CPU, 2),
            WorkerConfig(TaskType.THUMBNAIL_GENERATION, 1, ResourceType.CPU, 4),
        ]

        for config in default_configs:
            self.add_worker_pool(config)
