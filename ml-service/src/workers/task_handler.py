"""Task handler for ML Service Worker job consumption and result processing.

This module implements the process_ml_task handler that:
1. Consumes jobs from Redis ml_jobs queue (via arq)
2. Marks task as RUNNING in PostgreSQL
3. Runs ML inference using the model manager
4. Transforms results to ArtifactEnvelopes
5. Batch inserts artifacts to PostgreSQL
6. Marks task as COMPLETED
"""

import asyncio
import json
import logging
import os
from datetime import datetime
from uuid import uuid4

logger = logging.getLogger(__name__)


async def process_ml_task(
    ctx,
    task_id: str,
    task_type: str,
    video_id: str,
    video_path: str,
    config: dict | None = None,
) -> dict:
    """Process an ML task: run inference and persist results to PostgreSQL.

    This handler is called by arq when a job is consumed from the ml_jobs queue.
    It implements the processing pattern:
    1. Mark task as RUNNING in PostgreSQL
    2. Run ML inference using the model manager
    3. Transform results to ArtifactEnvelopes
    4. Batch insert artifacts to PostgreSQL
    5. Mark task as COMPLETED
    6. Sync projections for each artifact

    Args:
        ctx: arq job context
        task_id: Unique task identifier
        task_type: Type of task (e.g., 'object_detection')
        video_id: Video identifier
        video_path: Path to video file
        config: Optional task configuration

    Returns:
        Dictionary with task_id, status, and artifact_count

    Raises:
        asyncio.CancelledError: If task is cancelled via arq
        ValueError: If task parameters are invalid
        RuntimeError: If inference or database operations fail
    """
    session = None
    try:
        logger.info(f"üöÄ Dequeued task {task_id} ({task_type}) for video {video_id}")
        logger.debug(f"üìã Task config {task_id}: {config}")

        # Initialize database session
        from ..database.connection import get_scoped_db, remove_scoped_session

        session = get_scoped_db()
        logger.info(f"‚úÖ Database session initialized for task {task_id}")

        # Mark task as RUNNING
        from ..database.models import Task

        task = session.query(Task).filter(Task.task_id == task_id).first()
        if not task:
            raise ValueError(f"Task {task_id} not found in database")

        task.status = "running"
        task.started_at = datetime.utcnow()
        session.flush()  # Flush but don't commit yet
        logger.info(f"üìç Task {task_id} marked as RUNNING")

        # Initialize model manager for this task
        from src.services.model_manager import ModelManager

        model_cache_dir = os.getenv("MODEL_CACHE_DIR", "/models")
        os.environ["HF_HOME"] = os.path.join(model_cache_dir, "huggingface")
        os.environ["YOLO_HOME"] = os.path.join(model_cache_dir, "ultralytics")
        os.environ["EASYOCR_HOME"] = os.path.join(model_cache_dir, "easyocr")

        model_manager = ModelManager(cache_dir=model_cache_dir)
        logger.info(f"‚úÖ Model manager initialized for task {task_id}")

        # Map task type to inference function
        task_to_endpoint = {
            "object_detection": "objects",
            "face_detection": "faces",
            "transcription": "transcribe",
            "ocr": "ocr",
            "place_detection": "places",
            "scene_detection": "scenes",
            "metadata_extraction": "metadata",
            "thumbnail_extraction": "thumbnails",
            "thumbnail.extraction": "thumbnails",
        }
        endpoint = task_to_endpoint.get(task_type)
        if not endpoint:
            raise ValueError(f"Unknown task type: {task_type}")

        logger.info(f"üé¨ Starting {endpoint} inference on {video_path}")

        # Run inference based on task type
        if task_type == "object_detection":
            result = await model_manager.detect_objects(video_path, config or {})
        elif task_type == "face_detection":
            result = await model_manager.detect_faces(video_path, config or {})
        elif task_type == "transcription":
            result = await model_manager.transcribe_video(video_path, config or {})
        elif task_type == "ocr":
            result = await model_manager.extract_ocr(video_path, config or {})
        elif task_type == "place_detection":
            result = await model_manager.classify_places(video_path, config or {})
        elif task_type == "scene_detection":
            result = await model_manager.detect_scenes(video_path, config or {})
        elif task_type == "metadata_extraction":
            result = await model_manager.extract_metadata(video_path, config or {})
            # Update video metadata using the same session
            await _update_video_file_created_at(
                session, task.video_id, result, video_path
            )
        elif task_type == "thumbnail_extraction" or task_type == "thumbnail.extraction":
            # Thumbnail extraction is different - it generates files, not artifacts
            from src.workers.thumbnail_extractor import (
                collect_artifact_timestamps,
                extract_frame_with_ffmpeg,
                generate_thumbnails_idempotent,
            )

            # Collect unique timestamps from artifacts for this video
            timestamps = collect_artifact_timestamps(video_id, session)

            # Generate thumbnails idempotently (skips existing)
            stats = generate_thumbnails_idempotent(
                video_id=video_id,
                video_path=video_path,
                timestamps=timestamps,
                extract_frame_fn=extract_frame_with_ffmpeg,
            )

            logger.info(
                f"üñºÔ∏è Thumbnail extraction complete for {video_id}: "
                f"generated={stats.generated}, skipped={stats.skipped}, "
                f"failed={stats.failed}"
            )

            # Determine task status based on results
            # Failed if: all thumbnails failed (none generated, none skipped)
            # or if there were timestamps to process but all failed
            all_failed = (
                stats.failed > 0 and stats.generated == 0 and stats.total_timestamps > 0
            )

            if all_failed:
                task.status = "failed"
                task.error_message = f"All {stats.failed} thumbnail extractions failed"
                task.completed_at = datetime.utcnow()
                session.commit()
                logger.warning(
                    f"‚ùå Task {task_id} marked as FAILED: "
                    f"all {stats.failed} thumbnails failed to generate"
                )
                return {
                    "task_id": task_id,
                    "status": "failed",
                    "thumbnail_stats": stats.to_dict(),
                    "error": f"All {stats.failed} thumbnail extractions failed",
                }

            # Mark task as completed (some or all succeeded)
            task.status = "completed"
            task.completed_at = datetime.utcnow()
            session.commit()

            return {
                "task_id": task_id,
                "status": "completed",
                "thumbnail_stats": stats.to_dict(),
            }
        else:
            raise ValueError(f"Unknown task type: {task_type}")

        logger.info(f"‚úÖ Video processing complete for task {task_id} ({task_type})")

        # Convert result to dict if needed
        if hasattr(result, "dict"):
            result_dict = result.dict()
        else:
            result_dict = result

        logger.info(
            f"üìä Inference results: {len(result_dict.get('detections', []))} "
            f"detections/segments for task {task_id}"
        )

        # Transform results to ArtifactEnvelopes
        from ..domain.artifacts import ArtifactEnvelope

        run_id = str(uuid4())
        envelopes = []

        # Extract metadata from result
        config_hash = result_dict.get("config_hash", "")
        input_hash = result_dict.get("input_hash", "")
        producer = result_dict.get("producer", "ml-service")
        producer_version = result_dict.get("producer_version", "1.0.0")
        model_profile = result_dict.get("model_profile", "balanced")

        # Set producer info for metadata_extraction
        if task_type == "metadata_extraction":
            producer = "pyexiftool"
            producer_version = "0.5.5"
            model_profile = "balanced"

        # Map task types to artifact types
        task_to_artifact_type = {
            "object_detection": "object.detection",
            "face_detection": "face.detection",
            "transcription": "transcript.segment",
            "ocr": "ocr.text",
            "place_detection": "place.classification",
            "scene_detection": "scene",
            "metadata_extraction": "video.metadata",
        }

        artifact_type = task_to_artifact_type.get(task_type)
        if not artifact_type:
            raise ValueError(f"Unknown task type: {task_type}")

        # Map task types to result keys
        task_to_result_key = {
            "object_detection": "detections",
            "face_detection": "detections",
            "transcription": "segments",
            "ocr": "detections",
            "place_detection": "classifications",
            "scene_detection": "scenes",
            "metadata_extraction": "metadata",
        }

        result_key = task_to_result_key.get(task_type)
        if not result_key:
            raise ValueError(f"Unknown task type: {task_type}")

        # Extract detections/segments from response
        # For metadata_extraction, the result is a single object, not a list
        if task_type == "metadata_extraction":
            metadata = result_dict.get(result_key, {})
            if not metadata:
                logger.warning(
                    f"‚ö†Ô∏è  No metadata found in inference results for task {task_id}"
                )
                detections = []
            else:
                logger.info(
                    f"üîÑ Processing metadata into ArtifactEnvelope for task {task_id}"
                )
                logger.debug(f"Metadata dict: {metadata}")
                # For metadata_extraction, create a single artifact with the entire metadata
                try:
                    artifact_id = f"{video_id}_{task_type}_{run_id}_0"
                    payload_json = json.dumps(metadata)

                    # Metadata spans entire video (0 to duration)
                    duration_seconds = metadata.get("duration_seconds", 0)
                    span_start_ms = 0
                    span_end_ms = (
                        int(duration_seconds * 1000) if duration_seconds else 0
                    )

                    logger.debug(
                        f"Creating metadata artifact: duration_seconds={duration_seconds}, "
                        f"span_start_ms={span_start_ms}, span_end_ms={span_end_ms}"
                    )

                    envelope = ArtifactEnvelope(
                        artifact_id=artifact_id,
                        asset_id=video_id,
                        artifact_type=artifact_type,
                        schema_version=1,
                        span_start_ms=span_start_ms,
                        span_end_ms=span_end_ms,
                        payload_json=payload_json,
                        producer=producer,
                        producer_version=producer_version,
                        model_profile=model_profile,
                        config_hash=config_hash,
                        input_hash=input_hash,
                        run_id=run_id,
                        created_at=datetime.utcnow(),
                    )
                    envelopes.append(envelope)
                    logger.info(f"‚úÖ Created metadata artifact for task {task_id}")
                except (ValueError, KeyError) as e:
                    logger.error(
                        f"‚ùå Error creating metadata artifact for task {task_id}: {e}"
                    )
        else:
            detections = result_dict.get(result_key, [])
            if not detections:
                logger.warning(
                    f"‚ö†Ô∏è  No detections found in inference results for task {task_id}"
                )
            else:
                logger.info(
                    f"üîÑ Processing {len(detections)} detections into ArtifactEnvelopes "
                    f"for task {task_id}"
                )

            # Transform each detection to an ArtifactEnvelope
            for idx, detection in enumerate(detections):
                try:
                    # Generate unique artifact ID
                    artifact_id = f"{video_id}_{task_type}_{run_id}_{idx}"

                    # Extract time span (in milliseconds)
                    # For metadata_extraction, span covers entire video (0 to duration)
                    if task_type == "metadata_extraction":
                        # Get video duration from metadata if available
                        duration_seconds = detection.get("duration_seconds", 0)
                        span_start_ms = 0
                        span_end_ms = (
                            int(duration_seconds * 1000) if duration_seconds else 0
                        )
                        logger.debug(
                            f"Metadata artifact: duration_seconds={duration_seconds}, "
                            f"span_start_ms={span_start_ms}, span_end_ms={span_end_ms}"
                        )
                    # Some detections have explicit start_ms/end_ms
                    # (transcription, scenes)
                    elif "start_ms" in detection and "end_ms" in detection:
                        span_start_ms = int(detection.get("start_ms", 0))
                        span_end_ms = int(detection.get("end_ms", 0))
                    # Others have timestamp_ms (point-in-time detections)
                    elif "timestamp_ms" in detection:
                        # For point-in-time detections, use timestamp as
                        # both start and end
                        timestamp_ms = int(detection.get("timestamp_ms", 0))
                        span_start_ms = timestamp_ms
                        span_end_ms = timestamp_ms
                    else:
                        msg = (
                            f"‚ö†Ô∏è  No time information in detection {idx} "
                            f"for task {task_id}"
                        )
                        logger.warning(msg)
                        continue

                    # Validate time span
                    if span_start_ms < 0 or span_end_ms < 0:
                        logger.warning(
                            f"‚ö†Ô∏è  Invalid time span for detection {idx}: "
                            f"start={span_start_ms}, end={span_end_ms}"
                        )
                        continue

                    if span_start_ms > span_end_ms:
                        logger.warning(
                            f"‚ö†Ô∏è  Invalid time span for detection {idx}: "
                            f"start > end ({span_start_ms} > {span_end_ms})"
                        )
                        continue

                    # Serialize detection payload to JSON
                    payload_json = json.dumps(detection)

                    # Create ArtifactEnvelope
                    envelope = ArtifactEnvelope(
                        artifact_id=artifact_id,
                        asset_id=video_id,
                        artifact_type=artifact_type,
                        schema_version=1,
                        span_start_ms=span_start_ms,
                        span_end_ms=span_end_ms,
                        payload_json=payload_json,
                        producer=producer,
                        producer_version=producer_version,
                        model_profile=model_profile,
                        config_hash=config_hash,
                        input_hash=input_hash,
                        run_id=run_id,
                        created_at=datetime.utcnow(),
                    )

                    envelopes.append(envelope)

                except (ValueError, KeyError) as e:
                    logger.error(
                        f"‚ùå Error transforming detection {idx} for task {task_id}: {e}"
                    )
                    continue

            logger.info(
                f"‚úÖ Transformed {len(envelopes)} detections to ArtifactEnvelopes "
                f"for task {task_id}"
            )

        # Batch insert artifacts to PostgreSQL
        if envelopes:
            logger.info(
                f"üíæ Batch inserting {len(envelopes)} artifacts to database "
                f"for task {task_id} and video {video_id}"
            )

            from ..database.models import Artifact

            # Convert ArtifactEnvelope domain objects to ORM models
            orm_envelopes = []
            for envelope in envelopes:
                # Parse payload_json string to dict for proper JSONB storage
                # (envelope.payload_json is a JSON string, but JSONB column needs a dict)
                payload_dict = json.loads(envelope.payload_json)

                orm_envelope = Artifact(
                    artifact_id=envelope.artifact_id,
                    asset_id=envelope.asset_id,
                    artifact_type=envelope.artifact_type,
                    schema_version=envelope.schema_version,
                    span_start_ms=envelope.span_start_ms,
                    span_end_ms=envelope.span_end_ms,
                    payload_json=payload_dict,
                    producer=envelope.producer,
                    producer_version=envelope.producer_version,
                    model_profile=envelope.model_profile,
                    config_hash=envelope.config_hash,
                    input_hash=envelope.input_hash,
                    run_id=envelope.run_id,
                    created_at=envelope.created_at,
                )
                orm_envelopes.append(orm_envelope)

            # Batch insert
            session.add_all(orm_envelopes)
            session.flush()  # Flush but don't commit yet
            logger.info(
                f"‚úÖ Successfully inserted {len(orm_envelopes)} artifacts to "
                f"PostgreSQL for task {task_id}"
            )

            # Sync projections for each artifact
            logger.info(
                f"üîÑ Syncing projections for {len(envelopes)} artifacts "
                f"for task {task_id}"
            )

            from ..services.projection_sync_service import ProjectionSyncService

            projection_service = ProjectionSyncService(session)
            projection_errors = []
            for envelope in envelopes:
                try:
                    projection_service.sync_artifact(envelope)
                except Exception as e:
                    logger.warning(
                        f"‚ö†Ô∏è  Failed to sync projection for artifact "
                        f"{envelope.artifact_id}: {e}"
                    )
                    projection_errors.append((envelope.artifact_id, str(e)))

            if projection_errors:
                logger.warning(
                    f"‚ö†Ô∏è  {len(projection_errors)} projection sync errors occurred, "
                    f"rolling back transaction"
                )
                session.rollback()
                raise RuntimeError(
                    f"Projection sync failed for {len(projection_errors)} artifacts: "
                    f"{projection_errors}"
                )

            logger.info(
                f"‚úÖ Projection sync complete for task {task_id} "
                f"({len(envelopes)} artifacts)"
            )

        # Mark task as COMPLETED
        task.status = "completed"
        task.completed_at = datetime.utcnow()
        session.commit()  # Single commit at the end
        logger.info(
            f"‚úÖ Task {task_id} ({task_type}) marked as COMPLETED "
            f"({len(envelopes)} artifacts persisted)"
        )

        return {
            "task_id": task_id,
            "status": "completed",
            "artifact_count": len(envelopes),
        }

    except asyncio.CancelledError:
        logger.warning(f"‚ö†Ô∏è  Task {task_id} was cancelled via arq")
        if session:
            try:
                from ..database.models import Task

                task = session.query(Task).filter(Task.task_id == task_id).first()
                if task:
                    task.status = "cancelled"
                    session.commit()
                    logger.info(f"üìç Task {task_id} marked as CANCELLED")
            except Exception as e:
                logger.error(f"‚ùå Failed to mark task as cancelled: {e}")
        raise

    except Exception as e:
        logger.error(f"‚ùå Error processing task {task_id}: {e}", exc_info=True)

        # Mark task as FAILED
        if session:
            try:
                from ..database.models import Task

                task = session.query(Task).filter(Task.task_id == task_id).first()
                if task:
                    task.status = "failed"
                    task.error_message = str(e)
                    session.commit()
                    logger.info(f"üìç Task {task_id} marked as FAILED")
            except Exception as db_error:
                logger.error(f"‚ùå Failed to mark task as failed: {db_error}")

        raise RuntimeError(f"Failed to process task {task_id}: {e}")

    finally:
        # Close database session
        if session:
            try:
                session.commit()  # Ensure any pending changes are committed
            except Exception as e:
                logger.error(f"‚ùå Failed to commit session: {e}")
                try:
                    session.rollback()
                except Exception as rollback_error:
                    logger.error(f"‚ùå Failed to rollback session: {rollback_error}")
            logger.debug(f"Database session closed for task {task_id}")

        # Remove scoped session
        from ..database.connection import remove_scoped_session

        remove_scoped_session()
        logger.debug(f"Scoped session removed for task {task_id}")


async def _update_video_file_created_at(
    session, video_id: str, metadata_result: dict, video_path: str
) -> None:
    """Update video metadata from extraction results.

    Sets:
    1. file_created_at: EXIF create_date ‚Üí file mtime ‚Üí current timestamp
    2. duration: from metadata duration_seconds
    3. processed_at: current timestamp

    Args:
        session: SQLAlchemy session (shared with process_ml_task)
        video_id: Video identifier
        metadata_result: Result dict from metadata extraction
        video_path: Path to video file
    """
    from ..database.models import Video

    try:
        video = session.query(Video).filter(Video.video_id == video_id).first()
        if not video:
            logger.warning(f"Video {video_id} not found for metadata update")
            return

        file_created_at = None
        duration = None

        # Try to get create_date from metadata
        metadata_dict = metadata_result.get("metadata", {})
        if isinstance(metadata_dict, dict):
            # Extract duration
            duration_seconds = metadata_dict.get("duration_seconds")
            if duration_seconds:
                try:
                    duration = float(duration_seconds)
                    logger.debug(f"Extracted duration: {duration} seconds")
                except (ValueError, TypeError):
                    pass

            # Extract create_date
            create_date_str = metadata_dict.get("create_date")
            if create_date_str:
                try:
                    # Handle exiftool format: YYYY:MM:DD HH:MM:SS
                    if ":" in create_date_str and create_date_str[4] == ":":
                        # Replace colons with dashes in date part only
                        parts = create_date_str.split(" ")
                        date_part = parts[0].replace(":", "-")
                        time_part = parts[1] if len(parts) > 1 else "00:00:00"
                        iso_format = f"{date_part}T{time_part}"
                        file_created_at = datetime.fromisoformat(iso_format)
                    else:
                        # Try ISO format directly
                        file_created_at = datetime.fromisoformat(create_date_str)
                    logger.info(
                        f"‚úÖ Set file_created_at from EXIF: {file_created_at} "
                        f"for video {video_id}"
                    )
                except (ValueError, TypeError) as e:
                    logger.warning(
                        f"‚ö†Ô∏è  Failed to parse create_date '{create_date_str}': {e}"
                    )

        # Fallback to file system mtime
        if not file_created_at:
            try:
                mtime = os.path.getmtime(video_path)
                file_created_at = datetime.fromtimestamp(mtime)
                logger.info(
                    f"‚úÖ Set file_created_at from file mtime: {file_created_at} "
                    f"for video {video_id}"
                )
            except (OSError, ValueError) as e:
                logger.warning(f"‚ö†Ô∏è  Failed to get file mtime for {video_path}: {e}")

        # Fallback to current timestamp
        if not file_created_at:
            file_created_at = datetime.utcnow()
            logger.info(
                f"‚úÖ Set file_created_at to current timestamp: {file_created_at} "
                f"for video {video_id}"
            )

        # Update all video metadata fields in the shared session
        video.file_created_at = file_created_at
        if duration:
            video.duration = duration
        video.processed_at = datetime.utcnow()

        logger.debug(
            f"Updating video {video_id}: file_created_at={file_created_at}, "
            f"duration={duration}, processed_at={video.processed_at}"
        )
        logger.info(
            f"‚úÖ Updated video {video_id} metadata: "
            f"file_created_at={file_created_at}, duration={duration}"
        )

    except Exception as e:
        logger.error(
            f"‚ùå Error updating video metadata for {video_id}: {e}",
            exc_info=True,
        )
        raise
