version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: eioku
      POSTGRES_PASSWORD: eioku_dev
      POSTGRES_DB: eioku
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U eioku"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - eioku-dev

  valkey:
    image: valkey/valkey:8-alpine
    command: valkey-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - valkey_data:/data
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - eioku-dev

  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - backend
      - frontend
    networks:
      - eioku-dev

  backend:
    build:
      context: ../backend
      dockerfile: ../dev/Dockerfile.backend
    volumes:
      - ../backend:/app
      - ../test-videos:/media:ro
      - backend_models:/app/models
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://eioku:eioku_dev@postgres:5432/eioku
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    working_dir: /app
    depends_on:
      postgres:
        condition: service_healthy
    # Just run the app - dependencies already installed in image
    command: poetry run gunicorn src.main:app -w 1 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000 --reload --log-level debug --access-logfile -
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - eioku-dev

  frontend:
    build:
      context: ../frontend
      dockerfile: ../dev/Dockerfile.frontend
    volumes:
      - ../frontend:/app
      - /app/node_modules
    working_dir: /app
    command: npm run dev -- --host 0.0.0.0 --port 3000
    networks:
      - eioku-dev

  ml-service:
    build:
      context: ../ml-service
      dockerfile: ../dev/Dockerfile.ml-service
    volumes:
      - ../ml-service:/app
      - ml_models:/models
    environment:
      - PYTHONPATH=/app
      - GPU_CONCURRENCY=2
      - MODEL_CACHE_DIR=/models
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    working_dir: /app
    command: uvicorn src.main:app --host 0.0.0.0 --port 8001 --reload
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - eioku-dev

networks:
  eioku-dev:
    driver: bridge

volumes:
  postgres_data:
  valkey_data:
  ml_models:
