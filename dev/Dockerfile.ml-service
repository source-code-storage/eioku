# syntax=docker/dockerfile:1.4
FROM nvidia/cuda:12.6.0-cudnn-runtime-ubuntu22.04

# Install Python 3.10 and system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-dev \
    python3-pip \
    ffmpeg \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Make python3.10 the default python
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1

# Install Poetry
RUN pip install poetry
# Ensure poetry is on PATH
ENV PATH="/root/.local/bin:$PATH"

# Configure Poetry to install dependencies into global site-packages (not virtualenv)
ENV POETRY_VIRTUALENVS_CREATE=false

# Set CUDA library path - must be set before torch tries to load CUDA libraries
ENV LD_LIBRARY_PATH=/usr/local/cuda-12.6/targets/x86_64-linux/lib:/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH

WORKDIR /app

# Copy Poetry files only (for layer caching)
COPY ml-service/pyproject.toml ml-service/poetry.lock* ./

# Install dependencies (including dev tools like ruff, pytest)
RUN poetry install --no-root

# Copy application code
COPY ml-service/src ./src
COPY ml-service/gunicorn.conf.py ./gunicorn.conf.py

# Create model cache directories with proper permissions
RUN mkdir -p /models/ultralytics /models/easyocr /models/huggingface && \
    chmod 777 /models /models/ultralytics /models/easyocr /models/huggingface

# Expose port
EXPOSE 8001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8001/health')" || exit 1

# Override NVIDIA entrypoint to use our command
ENTRYPOINT []